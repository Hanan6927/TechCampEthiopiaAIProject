{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from opendatasets) (4.48.2)\n",
      "Collecting click\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 1.9 MB/s             \n",
      "\u001b[?25hCollecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "     |████████████████████████████████| 58 kB 1.2 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from click->opendatasets) (1.7.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle->opendatasets) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle->opendatasets) (2.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle->opendatasets) (2.24.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-6.1.1-py2.py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle->opendatasets) (1.25.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->click->opendatasets) (3.1.0)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 13.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=9a8798a5a2fdb68cfac57b3ad9d503927c1bc4d772f6635fcfd64a0e3c54e6dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/47/e4/44a4ba1b7dfd53faaa35f59f1175e123b213ff401a8a56876b\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle, click, opendatasets\n",
      "Successfully installed click-8.0.4 kaggle-1.5.12 opendatasets-0.1.20 python-slugify-6.1.1 text-unidecode-1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n",
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  hananmiftah\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14.0M/658M [00:00<00:04, 143MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading plantdisease.zip to ./plantdisease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 658M/658M [00:04<00:00, 153MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets\n",
    "import opendatasets as od\n",
    "from tensorflow import keras\n",
    "\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)\n",
    "base_model.trainable = False\n",
    "od.download(\"https://www.kaggle.com/emmarex/plantdisease\")\n",
    "\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "outputs = keras.layers.Dense(units = 15, activation='softmax')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split-folders in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 20639 files [00:02, 9892.42 files/s] \n"
     ]
    }
   ],
   "source": [
    "!pip install split-folders\n",
    "import splitfolders\n",
    "splitfolders.ratio('plantdisease/plantvillage/PlantVillage/', output=\"output\", seed=1337, ratio=(.8, 0.1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True) # we don't expect Bo to be upside-down so we will not flip vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16504 images belonging to 15 classes.\n",
      "Found 2058 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_it = datagen.flow_from_directory('output/train/', \n",
    "                                       target_size=(224, 224), \n",
    "                                       color_mode='rgb', \n",
    "                                       class_mode='categorical', \n",
    "                                       batch_size=8)\n",
    "# load and iterate validation dataset\n",
    "valid_it = datagen.flow_from_directory('output/val/', \n",
    "                                      target_size=(224, 224), \n",
    "                                      color_mode='rgb', \n",
    "                                      class_mode='categorical', \n",
    "                                      batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2063/2063 [==============================] - 203s 99ms/step - loss: 0.9354 - accuracy: 0.7298 - val_loss: 0.5034 - val_accuracy: 0.8440\n",
      "Epoch 2/20\n",
      "2063/2063 [==============================] - 200s 97ms/step - loss: 0.4473 - accuracy: 0.8612 - val_loss: 0.3927 - val_accuracy: 0.8819\n",
      "Epoch 3/20\n",
      "2063/2063 [==============================] - 200s 97ms/step - loss: 0.4001 - accuracy: 0.8772 - val_loss: 0.3855 - val_accuracy: 0.8853\n",
      "Epoch 4/20\n",
      " 370/2063 [====>.........................] - ETA: 2:25 - loss: 0.3842 - accuracy: 0.8807"
     ]
    }
   ],
   "source": [
    "model.fit(train_it, steps_per_epoch=train_it.samples/train_it.batch_size, validation_data=valid_it, validation_steps=valid_it.samples/valid_it.batch_size, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
